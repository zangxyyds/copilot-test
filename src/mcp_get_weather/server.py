import contextlib
import logging
import os
import time
from collections.abc import AsyncIterator

import anyio
import click
import httpx
import mcp.types as types
from mcp.server.lowlevel import Server
from mcp.server.streamable_http_manager import StreamableHTTPSessionManager
from starlette.applications import Starlette
from starlette.routing import Mount
from starlette.types import Receive, Scope, Send

# ---------------------------------------------------------------------------
# Weather helpers
# ---------------------------------------------------------------------------
OPENWEATHER_URL = "https://api.openweathermap.org/data/2.5/weather"
DEFAULT_UNITS = "metric"  # use Celsius by default
DEFAULT_LANG = "zh_cn"  # Chinese descriptions
CACHE_TTL = 300  # Cache weather data for 5 minutes


# Simple in-memory cache for weather data
class WeatherCache:
    """Simple time-based cache for weather data."""

    def __init__(self, ttl: int = CACHE_TTL):
        self.ttl = ttl
        self._cache: dict[str, tuple[dict, float]] = {}

    def get(self, key: str) -> dict[str, str] | None:
        """Get cached data if not expired."""
        if key in self._cache:
            data, timestamp = self._cache[key]
            if time.time() - timestamp < self.ttl:
                return data
            # Remove expired entry
            del self._cache[key]
        return None

    def set(self, key: str, value: dict[str, str]) -> None:
        """Store data with current timestamp."""
        self._cache[key] = (value, time.time())


async def fetch_weather(city: str, api_key: str, client: httpx.AsyncClient, cache: WeatherCache) -> dict[str, str]:
    """Call OpenWeather API and return a simplified weather dict.

    Uses provided client for connection reuse and cache to reduce API calls.

    Raises:
        httpx.HTTPStatusError: if the response has a non-2xx status.
    """
    # Check cache first
    cache_key = city.lower()
    cached_data = cache.get(cache_key)
    if cached_data:
        return cached_data

    params = {
        "q": city,
        "appid": api_key,
        "units": DEFAULT_UNITS,
        "lang": DEFAULT_LANG,
    }
    r = await client.get(OPENWEATHER_URL, params=params)
    r.raise_for_status()
    data = r.json()
    # Extract a concise summary
    weather_main = data["weather"][0]["main"]
    description = data["weather"][0]["description"]
    temp = data["main"]["temp"]
    feels_like = data["main"]["feels_like"]
    humidity = data["main"]["humidity"]
    result = {
        "city": city,
        "weather": weather_main,
        "description": description,
        "temp": f"{temp}Â°C",
        "feels_like": f"{feels_like}Â°C",
        "humidity": f"{humidity}%",
    }
    # Store in cache
    cache.set(cache_key, result)
    return result


@click.command()
@click.option("--port", default=3000, help="Port to listen on for HTTP")
@click.option(
    "--api-key",
    envvar="OPENWEATHER_API_KEY",
    required=True,
    help="OpenWeather API key (or set OPENWEATHER_API_KEY env var)",
)
@click.option(
    "--log-level",
    default="INFO",
    help="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)",
)
@click.option(
    "--json-response",
    is_flag=True,
    default=False,
    help="Enable JSON responses instead of SSE streams",
)
def main(port: int, api_key: str, log_level: str, json_response: bool) -> int:
    """Run an MCP weather server using Streamable HTTP transport."""

    # ---------------------- Configure logging ----------------------
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )
    logger = logging.getLogger("weather-server")

    # ---------------------- Create MCP Server ----------------------
    app = Server("mcp-streamable-http-weather")

    # ---------------------- Shared resources ----------------------
    # Create shared httpx client and cache for efficient resource use
    http_client: httpx.AsyncClient | None = None
    weather_cache = WeatherCache()

    # ---------------------- Tool implementation -------------------
    @app.call_tool()
    async def call_tool(name: str, arguments: dict) -> list[types.TextContent]:
        """Handle the 'get-weather' tool call."""
        nonlocal http_client
        ctx = app.request_context
        city = arguments.get("location")
        if not city:
            raise ValueError("'location' is required in arguments")

        # Send an initial log message so the client sees streaming early.
        await ctx.session.send_log_message(
            level="info",
            data=f"Fetching weather for {city}â€¦",
            logger="weather",
            related_request_id=ctx.request_id,
        )

        try:
            weather = await fetch_weather(city, api_key, http_client, weather_cache)
        except Exception as err:
            # Stream the error to the client and re-raise so MCP returns error.
            await ctx.session.send_log_message(
                level="error",
                data=str(err),
                logger="weather",
                related_request_id=ctx.request_id,
            )
            raise

        # Stream a success notification (optional)
        await ctx.session.send_log_message(
            level="info",
            data="Weather data fetched successfully!",
            logger="weather",
            related_request_id=ctx.request_id,
        )

        # Compose human-readable summary for the final return value.
        summary = (
            f"{weather['city']}ï¼š{weather['description']}ï¼Œæ¸©åº¦ {weather['temp']}ï¼Œ"
            f"ä½“æ„Ÿ {weather['feels_like']}ï¼Œæ¹¿åº¦ {weather['humidity']}ã€‚"
        )

        return [
            types.TextContent(type="text", text=summary),
        ]

    # ---------------------- Tool registry -------------------------
    @app.list_tools()
    async def list_tools() -> list[types.Tool]:
        """Expose available tools to the LLM."""
        return [
            types.Tool(
                name="get-weather",
                description="æŸ¥è¯¢æŒ‡å®šåŸŽå¸‚çš„å®žæ—¶å¤©æ°”ï¼ˆOpenWeather æ•°æ®ï¼‰",
                inputSchema={
                    "type": "object",
                    "required": ["location"],
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "åŸŽå¸‚çš„è‹±æ–‡åç§°ï¼Œå¦‚ 'Beijing'",
                        }
                    },
                },
            )
        ]

    # ---------------------- Session manager -----------------------
    session_manager = StreamableHTTPSessionManager(
        app=app,
        event_store=None,  # æ— çŠ¶æ€ï¼›ä¸ä¿å­˜åŽ†å²äº‹ä»¶
        json_response=json_response,
        stateless=True,
    )

    async def handle_streamable_http(scope: Scope, receive: Receive, send: Send) -> None:  # noqa: D401,E501
        await session_manager.handle_request(scope, receive, send)

    # ---------------------- Lifespan Management --------------------
    @contextlib.asynccontextmanager
    async def lifespan(app: Starlette) -> AsyncIterator[None]:
        nonlocal http_client
        # Initialize shared HTTP client
        http_client = httpx.AsyncClient(timeout=10)
        async with session_manager.run():
            logger.info("Weather MCP server started! ðŸš€")
            try:
                yield
            finally:
                logger.info("Weather MCP server shutting downâ€¦")
                # Clean up HTTP client
                await http_client.aclose()

    # ---------------------- ASGI app + Uvicorn ---------------------
    starlette_app = Starlette(
        debug=False,
        routes=[Mount("/mcp", app=handle_streamable_http)],
        lifespan=lifespan,
    )

    import uvicorn

    uvicorn.run(starlette_app, host="0.0.0.0", port=port)

    return 0


if __name__ == "__main__":
    main()
